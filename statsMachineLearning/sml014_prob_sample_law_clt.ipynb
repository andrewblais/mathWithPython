{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_Probability Sampling, Law of Large Numbers, ..._**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Monte Carlo Sampling to take the mean of increasing numbers of samples from a population distribution.\n",
    "\n",
    "The mean of more and more samples means the estimate gets closer and closer to the population's mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "N = 34203\n",
    "\n",
    "rng = np.random.default_rng(1042)\n",
    "population = rng.normal(loc=0.0, scale=1.0, size=N)\n",
    "mu = np.mean(population)\n",
    "\n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "\n",
    "def mc_sampling(sample_size):\n",
    "    samples = rng.choice(population, size=(num_samples, sample_size))\n",
    "    means = samples.mean(axis=1)\n",
    "    return means.mean(), means.std(ddof=1)\n",
    "\n",
    "\n",
    "for i in range(10, 10010, 1000):\n",
    "    mean_means, std_means = mc_sampling(i)\n",
    "    print(f\"{mean_means - mu:5f}\")\n",
    "    print(f\"{std_means:5f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Creating a Distribution of Sample Estimates..._**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Scientific Question #2: Are giraffes taller than slow lorises?_**\n",
    "\n",
    "-   In an earlier lesson we wondered when we actually need Probability & Statistics.\n",
    "\n",
    "-   For a question like this, we don't need Probability Theory, we don't need inferential statistics.\n",
    "\n",
    "-   This is because the shortest giraffe will be taller than the tallest slow loris.\n",
    "\n",
    "-   Not a meaningful question, but a useful didactic tool\n",
    "\n",
    "Now we go ahead and answer it:\n",
    "\n",
    "We cannot measure the entire population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **\\_So we measure a **SAMPLE** from each group:\\_**\n",
    "\n",
    "-   Measure a small sample of giraffes vs. a small sample of slow lorises.\n",
    "\n",
    "-   Then compute the difference between these two specific samples' averages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Repeat the Process for a Different Sample:_**\n",
    "\n",
    "-   Take another random group of giraffes and another random group of slow lorises.\n",
    "\n",
    "-   Again measure the difference in their means.\n",
    "\n",
    "-   The difference from the first comparison is unlikely to be identical to the difference from the second comparision, but we expect them to be comparable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo Sampling is a fancier term for what we did in the previous lesson:\n",
    "\n",
    "-   Randomly sampling data from a distribution in order to use that randomness to estimate an unknown parameter or unknown function in that population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Take Many Samples:_**\n",
    "\n",
    "Averaging together many samples will approximate the true population mean (see lecture on _Law of Large Numbers_).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wouldn't trust the average height of a population based on one individual.\n",
    "\n",
    "So we measure a lot of people and average together with the key underlying assumption:\n",
    "\n",
    "-   Variability is both positive and negative.\n",
    "\n",
    "-   There's variability both _above_ and _below_ the average height.\n",
    "\n",
    "-   By averaging together we get a convergence to the true population mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the theoretical normal appears almost flat.\n",
    "\n",
    "It's so finely discretized relative to the sample distribution, which is only discretized into `10` or so bins.\n",
    "\n",
    "The theoretical is discretized into `10101` bins.\n",
    "\n",
    "These distributions can be tricky to normalize in a way that facilitates a visual comparison in the same plot.\n",
    "\n",
    "Commenting out this normalization and ensuring `hist(density=True)` creates a plot where both distributions are normalized to a good range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# A 'theoretical' normal distribution...\n",
    "#  not a true theoretical normal distribution\n",
    "#  as we're discretizing on a computer. 10101\n",
    "#  points is a good discretization rate, though:\n",
    "x = np.linspace(-5, 5, 10101)\n",
    "theo_norm_dist = stats.norm.pdf(x)\n",
    "\n",
    "# Compare against histogram, an empirical\n",
    "#  distribution of sample data randomly\n",
    "#  drawn from normal distribution:\n",
    "num_samples = 40\n",
    "# Initialize:\n",
    "sample_data = np.zeros(num_samples)\n",
    "\n",
    "# Run the experiment. Using for loop to clarify that\n",
    "#  this is an experiment we're running. Adding a random\n",
    "#  number for each iteration without consideration for\n",
    "#  the other random numbers in the experiment:\n",
    "for exp_i in range(num_samples):\n",
    "    sample_data[exp_i] = np.random.randn()\n",
    "\n",
    "# Plot the results:\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.hist(sample_data, density=True, label=\"Empirical/Sample Distribution\")\n",
    "plt.plot(x, theo_norm_dist, 'r', lw=3, label=\"Theoretical/Population Distribution\")\n",
    "plt.xlabel(\"Data Values\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 10101)\n",
    "theo_norm_dist = stats.norm.pdf(x)\n",
    "\n",
    "# Normalize to pdf:\n",
    "theo_norm_dist = theo_norm_dist * np.mean(np.diff(x))\n",
    "\n",
    "num_samples = 400\n",
    "sample_data = np.zeros(num_samples)\n",
    "\n",
    "for exp_i in range(num_samples):\n",
    "    sample_data[exp_i] = np.random.randn()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.hist(sample_data, density=True, label=\"Empirical/Sample Distribution\")\n",
    "plt.plot(x, theo_norm_dist, 'r', lw=3, label=\"Theoretical/Population Distribution\")\n",
    "plt.xlabel(\"Data Values\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the theoretical normal appears almost flat.\n",
    "\n",
    "It's so finely discretized relative to the sample distribution, which is only discretized into `10` or so bins.\n",
    "\n",
    "The theoretical is discretized into `10101` bins.\n",
    "\n",
    "These distributions can be tricky to normalize in a way that facilitates a visual comparison in the same plot.\n",
    "\n",
    "Commenting out this normalization and ensuring `hist(density=True)` creates a plot where both distributions are normalized to a good range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 10101)\n",
    "theo_norm_dist = stats.norm.pdf(x)\n",
    "\n",
    "# Normalize to pdf:\n",
    "# theo_norm_dist = theo_norm_dist * np.mean(np.diff(x))\n",
    "\n",
    "num_samples = 400\n",
    "sample_data = np.zeros(num_samples)\n",
    "\n",
    "for exp_i in range(num_samples):\n",
    "    sample_data[exp_i] = np.random.randn()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.hist(sample_data, density=True, label=\"Empirical/Sample Distribution\")\n",
    "plt.plot(x, theo_norm_dist, 'r', lw=3, label=\"Theoretical/Population Distribution\")\n",
    "plt.xlabel(\"Data Values\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the mean of samples of a known distribution...\n",
    "\n",
    "# # Generate population data with known mean...\n",
    "# Imagine this is all the people in Amsterdam:\n",
    "population_n = 1000000\n",
    "# This is our ENTIRE population. Imagine we're asking\n",
    "#  each person what they think about rain. Positive\n",
    "#  means you like rain, negative you don't like rain:\n",
    "population = np.random.randn(population_n)\n",
    "\n",
    "# Subtract mean to force average to 0, so this\n",
    "#  means population average is neutral feelings\n",
    "#  about rain:\n",
    "population = population - np.mean(population)\n",
    "\n",
    "# Draw a random sample of 30. Asking 30 random Amsterdam\n",
    "#  residents what they think about rain:\n",
    "sample_size = 30\n",
    "\n",
    "# The we take the average of this sample. We gather the\n",
    "#  indices to select from the population:\n",
    "sample_indices = np.random.randint(0, population_n, sample_size)\n",
    "sample_mean = np.mean(population[sample_indices])\n",
    "\n",
    "# # How does the sample mean compare to the population mean?\n",
    "print(np.round(np.mean(population), 13))\n",
    "print(np.round(sample_mean, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = np.arange(30, 1000)\n",
    "sample_means = np.zeros(len(sample_sizes))\n",
    "\n",
    "for samp_i in range(len(sample_sizes)):\n",
    "    # Nearly the same code as before:\n",
    "    sample_index = np.random.randint(0, population_n, sample_sizes[samp_i])\n",
    "    sample_means[samp_i] = np.mean(population[sample_index])\n",
    "\n",
    "# Show the results:\n",
    "plt.plot(sample_sizes, sample_means, 's-')\n",
    "# Constant:\n",
    "plt.plot(sample_sizes[[0, -1]], [np.mean(population), np.mean(population)], 'r', lw=3)\n",
    "plt.xlabel(\"Sample Size\")\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.legend((\"Sample Means\", \"Population Mean\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Expected Value vs. Average: Example_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine an 'illegal' (weighted) die, where the chances of getting each of the six sides aren't equal:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Side 1: $p = \\frac{1}{4}$**\n",
    "\n",
    "##### **Side 2: $p = \\frac{1}{4}$**\n",
    "\n",
    "##### **Side 3: $p = \\frac{1}{8}$**\n",
    "\n",
    "##### **Side 4: $p = \\frac{1}{8}$**\n",
    "\n",
    "##### **Side 5: $p = \\frac{1}{8}$**\n",
    "\n",
    "##### **Side 6: $p = \\frac{1}{8}$**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Quick Sanity Check:_\n",
    "\n",
    "-   Do the possible values all add up to $1$?\n",
    "\n",
    "-   Are the possibilities _exclusive_?\n",
    "\n",
    "-   We're excluding the possibility of the die landing on an edge.\n",
    "\n",
    "Now we can talk seriously about the Probability Mass Distribution of this die...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_What is the Expected Value of this die?_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Reminder of formula for expected value:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\Large\n",
    "    \\mathbf{E}[X]\n",
    "    \\; = \\;\n",
    "    \\sum_{i = 1}^n\n",
    "    \\;\n",
    "    x_i \\, p_i\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\Large\n",
    "    \\begin{matrix}\n",
    "        \\text{.} \\; p = \\frac{1}{4} & &\n",
    "        \\text{..} \\; p = \\frac{1}{4} \\\\ \\\\\n",
    "        \\text{:.} \\; p = \\frac{1}{8} & &\n",
    "        \\text{::} \\; p = \\frac{1}{8} \\\\ \\\\\n",
    "        \\text{::.} \\; p = \\frac{1}{8} & &\n",
    "        \\text{:::} \\; p = \\frac{1}{8}\n",
    "    \\end{matrix}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_anb:_\n",
    "\n",
    "I think it's exactly the same as the fractions.\n",
    "\n",
    "_e.g.,_ `1` has a `1/4` expected value, etc...\n",
    "\n",
    "Multiply $p_i$ times $x_i$. But $x_i$ isn't the number you rolled, rather the width of its bin, `1`.\n",
    "\n",
    "Or is the question asking what is the most likely result?\n",
    "\n",
    "I don't know, in that case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Mike:_\n",
    "\n",
    "We compute this by literally writing out the formula:\n",
    "\n",
    "$\n",
    "\\Large\n",
    "    \\begin{aligned}\n",
    "        & \\mathbf{E}[X] \\; = \\; \\sum_{i = 1}^n \\; x_i \\, p_i\n",
    "        \\\\ \\\\\n",
    "        & = 1p_1 + 2p_2 + 3p_3 + 4p_4 + 5p_5 + 6p_6\n",
    "        \\\\ \\\\\n",
    "        & = \\frac{1}{4} + \\frac{2}{4} + \\frac{3}{8} + \\frac{4}{8} + \\frac{5}{8} + \\frac{6}{8}\n",
    "        \\\\ \\\\\n",
    "        & = 3\n",
    "    \\end{aligned}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_anb:_\n",
    "\n",
    "-   I didn't realize you could plug the actual values in as $x_i$.\n",
    "\n",
    "-   For some reason I was thinking that's the index.\n",
    "\n",
    "-   I'd lost the thread on this concept, but it's clicking now...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't actually collect a single data point to compute this Expected Value.\n",
    "\n",
    "We can compute this expected value knowing **ALL THE PROBABILITIES OF ALL THE POSSIBILITIES**.\n",
    "\n",
    "So no data was required to compute the expected value...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Computing the Average:_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In contrast** with computing the average:\n",
    "\n",
    "-   To compute the average of a sample, we need sample data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine `8` random rolls of the loaded die:\n",
    "\n",
    "$1 \\qquad 3 \\qquad 4 \\qquad 4 \\qquad 4 \\qquad 3 \\qquad 2 \\qquad 5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average of this sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_anb:_\n",
    "\n",
    "-   `(1 + 3 + 4 + 4 + 4 + 3 + 2 + 5) / 8`\n",
    "\n",
    "-   `26 / 8`\n",
    "\n",
    "-   `3 2/8`\n",
    "\n",
    "-   `3 1/4`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct.\n",
    "\n",
    "`3.25` is the **Average** of the sample.\n",
    "\n",
    "The **Expected Value** is `3`.\n",
    "\n",
    "The average can vary from sample to sample.\n",
    "\n",
    "Would the average of many averages of many samples converge to the expected value?\n",
    "\n",
    "No, they're not necessarily the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the expected value requires no data, not a single data point.\n",
    "\n",
    "Whereas we do need data to compute the average.\n",
    "\n",
    "_anb:_ I don't understand why that means the average of many samples' averages won't converge toward the expected value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 style=\"color: goldenrod; font-weight: 500;\">\n",
    "\n",
    "$\\textcolor{dodgerblue}{A}$ and $\\textcolor{darkturquoise}{B}$ are independent when knowing\n",
    "<br>\n",
    "$\\textcolor{ivory}{P}(\\textcolor{dodgerblue}{A})$ provides no information about $\\textcolor{ivory}{P}(\\textcolor{darkturquoise}{B})$\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\huge\n",
    "    P (\\textcolor{dodgerblue}{A} \\cap \\textcolor{darkturquoise}{B})\n",
    "    \\; = \\;\n",
    "    P (\\textcolor{dodgerblue}{A}) \\ P (\\textcolor{darkturquoise}{B})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The probability of $A \\cap B$ ('$A$ intersection with $B$'), if the two events are independent of each other is equal to the probability of $A$ times the probability of $B$\"\n",
    "\n",
    "The probability of their intersection is equal to the product of the two probabilities on their own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px #5EDC1F; width: 70%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $A$ and $B$ are **NOT** independent (if $A$ and $B$ are dependent), then the definition of $A$ intersect $B$ changes:\n",
    "\n",
    "-   The probability of A given B times the probability of B...\n",
    "\n",
    "-   Reworking the original equation a bit.\n",
    "\n",
    "-   More on this later...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GENERATE TWO LONG-SPIKE TIME SERIES.\n",
    "# #  More like 'plateaus', 0 could correspond\n",
    "# #  to sunny days, 1 to rainy days...\n",
    "\n",
    "N = 10000\n",
    "# a.u. (arbitrary units) but must be even num:\n",
    "spike_dur = 10\n",
    "# In proportion to num points:\n",
    "spike_num_a = 0.01\n",
    "spike_num_b = 0.05\n",
    "\n",
    "# Initialize to zeros:\n",
    "spike_ts1 = np.zeros(N)\n",
    "spike_ts2 = np.zeros(N)\n",
    "\n",
    "# # Populate time series 1. Generate a bunch of\n",
    "# #  random ints to be the 'spike centers'.\n",
    "spike_times_1 = np.random.randint(0, N, int(N * spike_num_a))\n",
    "\n",
    "# Flex out spikes (loops per spike). Loop through all\n",
    "#  the ints and specify that from the spike onset (center)\n",
    "#  time +- spike_dur/2 gets turned to 1's:\n",
    "for spike_i in range(len(spike_times_1)):\n",
    "\n",
    "    # Find boundaries. Think carefully about these two lines.\n",
    "    #  They account for places where we might have spikes exactly\n",
    "    #  at the boundaries. Prevents indexing error if spike center\n",
    "    #  is really close to beginning or end of time series:\n",
    "    bound_pre = int(max(0, spike_times_1[spike_i] - spike_dur / 2))\n",
    "    bound_post = int(min(N, spike_times_1[spike_i] + spike_dur / 2))\n",
    "\n",
    "    # Fill in with ones:\n",
    "    spike_ts1[bound_pre:bound_post] = 1\n",
    "\n",
    "# # Repeat for time series 2:\n",
    "spike_times_2 = np.random.randint(0, N, int(N * spike_num_b))\n",
    "# Alternatively, induce strong conditional probability:\n",
    "# spike_times_2[:len(spike_times_1)] = spike_times_1\n",
    "\n",
    "# Flex out spikes (loops per spike):\n",
    "for spike_i in range(len(spike_times_2)):\n",
    "\n",
    "    # Find boundaries:\n",
    "    bound_pre = int(max(0, spike_times_2[spike_i] - spike_dur / 2))\n",
    "    bound_post = int(min(N, spike_times_2[spike_i] + spike_dur / 2))\n",
    "\n",
    "    # Fill in with ones:\n",
    "    spike_ts2[bound_pre:bound_post] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(N), spike_ts1, range(N), spike_ts2)\n",
    "plt.plot(range(N), spike_ts1, lw=3, c='goldenrod')\n",
    "plt.plot(range(N), spike_ts2, ls='--', c='dodgerblue')\n",
    "plt.ylim([0, 1.2])\n",
    "# Zoom in:\n",
    "plt.xlim([2000, 2500])\n",
    "# plt.xlim([2000, 2250])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities. Two ways of computing the\n",
    "#  average:\n",
    "prob_a = sum(spike_ts1 == 1) / N\n",
    "# Since the data is simplified to 0 or\n",
    "#  1, we can simply take the mean:\n",
    "prob_b = np.mean(spike_ts2)\n",
    "\n",
    "# Joint probability. spike_ts1 + spike_ts2 vals\n",
    "#  will be either 0, 1 (spike in one or other\n",
    "#  channel) or 2 (spike in both channels):\n",
    "prob_ab = np.mean(spike_ts1 + spike_ts2 == 2)\n",
    "\n",
    "print(prob_a, prob_b, prob_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(A|B):\n",
    "p_a_given_b = prob_ab / prob_b\n",
    "\n",
    "# P(B|A), scale by the probability\n",
    "#  of a:\n",
    "p_b_given_a = prob_ab / prob_a\n",
    "\n",
    "# Print a report:\n",
    "print(\"P(A) = %g\" % prob_a)\n",
    "print(\"P(A|B) = %g\" % p_a_given_b)\n",
    "print(\"P(B) = %g\" % prob_b)\n",
    "print(\"P(B|A) = %g\" % p_b_given_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "spike_dur = 10\n",
    "spike_num_a = 0.01\n",
    "spike_num_b = 0.05\n",
    "\n",
    "spike_ts1 = np.zeros(N)\n",
    "spike_ts2 = np.zeros(N)\n",
    "\n",
    "spike_times_1 = np.random.randint(0, N, int(N * spike_num_a))\n",
    "for spike_i in range(len(spike_times_1)):\n",
    "    bound_pre = int(max(0, spike_times_1[spike_i] - spike_dur / 2))\n",
    "    bound_post = int(min(N, spike_times_1[spike_i] + spike_dur / 2))\n",
    "    spike_ts1[bound_pre:bound_post] = 1\n",
    "\n",
    "spike_times_2 = np.random.randint(0, N, int(N * spike_num_b))\n",
    "spike_times_2[: len(spike_times_1)] = spike_times_1\n",
    "for spike_i in range(len(spike_times_2)):\n",
    "    bound_pre = int(max(0, spike_times_2[spike_i] - spike_dur / 2))\n",
    "    bound_post = int(min(N, spike_times_2[spike_i] + spike_dur / 2))\n",
    "    spike_ts2[bound_pre:bound_post] = 1\n",
    "\n",
    "prob_a = sum(spike_ts1 == 1) / N\n",
    "prob_b = np.mean(spike_ts2)\n",
    "prob_ab = np.mean(spike_ts1 + spike_ts2 == 2)\n",
    "\n",
    "print(prob_a, prob_b, prob_ab)\n",
    "\n",
    "p_a_given_b = prob_ab / prob_b\n",
    "p_b_given_a = prob_ab / prob_a\n",
    "\n",
    "print(\"P(A) = %g\" % prob_a)\n",
    "print(\"P(A|B) = %g\" % p_a_given_b)\n",
    "print(\"P(B) = %g\" % prob_b)\n",
    "print(\"P(B|A) = %g\" % p_b_given_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret and read probabilities off a Tree Diagram:\n",
    "\n",
    "-   Start from the beginning\n",
    "\n",
    "-   Move along each branch as appropriate\n",
    "\n",
    "-   If starting from '`A`', or answering a question about a conditional probability, just start immediately from whichever node is the conditional.\n",
    "\n",
    "-   To find the probabilities in total, start from the beginning and go through each probability, multiplying all the branches as you go through them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 style=\"color: dodgerblue; font-weight: 500; text-shadow: goldenrod 0.05rem -0.05rem 0.65rem; text-align: center;\">\n",
    "\n",
    "As the number of experiment repetitions increases, the average of the sample means better approximates the population mean.\n",
    "\n",
    "</font>\n",
    "\n",
    "<font size=2>\n",
    "\n",
    "_We typically don't know the true population mean. If we did, we wouldn't have to do the experiment._\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\huge\n",
    "    \\lim_{n \\to \\infty} \\; P(\\lvert \\bar{x}_n - \\mu \\rvert > \\epsilon) = 0\n",
    "\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anb:\n",
    "import numpy as np\n",
    "\n",
    "machine_epsilon_float64 = np.finfo(float).eps\n",
    "print(\"machine_epsilon_float64:\", machine_epsilon_float64)\n",
    "machine_epsilon_float32 = np.finfo(np.float32).eps\n",
    "print(\"machine_epsilon_float32:\", machine_epsilon_float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Import Libraries === #\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Example with Rolling a Die === #\n",
    "\n",
    "# Die probabilities (weighted, loaded, 'unfair'):\n",
    "face_1 = 2 / 8\n",
    "face_2 = 2 / 8\n",
    "face_3 = 1 / 8\n",
    "face_4 = 1 / 8\n",
    "face_5 = 1 / 8\n",
    "face_6 = 1 / 8\n",
    "\n",
    "# If truly a probability mass function, the\n",
    "#  probabilities should sum to 1, confirm:\n",
    "sum_probs = face_1 + face_2 + face_3 + face_4 + face_5 + face_6\n",
    "# print(\"Sum of probabilities of weighted die:\", sum_probs)  # 1.0\n",
    "\n",
    "# Expected value. Sum of (value * probability of\n",
    "#  getting that value). Rolling a 1 on the\n",
    "#  die * a probability of getting that 1, etc...:\n",
    "exp_val = 1 * face_1 + 2 * face_2 + 3 * face_3 + 4 * face_4 + 5 * face_5 + 6 * face_6\n",
    "print(\"Expected value of the weighted die:\", exp_val)  # 3.0\n",
    "\n",
    "# Generate \"population\". Generating a 'seed' of\n",
    "#  a population based on their probabilities of\n",
    "#  occurences. Rolling a 1 or 2 are each twice\n",
    "#  more likely than 3, 4, 5 or 6, so we take the\n",
    "#  seed vector and keep concatenating it on\n",
    "#  itself\n",
    "population = [1, 1, 2, 2, 3, 4, 5, 6]\n",
    "for _ in range(20):\n",
    "    population = np.hstack((population, population))\n",
    "\n",
    "\n",
    "n_pop = len(population)\n",
    "# Over 8,000,000 die rolls:\n",
    "# print(\"Number of elements in the population:\", n_pop)  # 8388608\n",
    "\n",
    "# Draw random sample of 8 rolls from population,\n",
    "#  just like randomly sampling from our population\n",
    "#  8 times:\n",
    "n_sample = 8\n",
    "sample = np.random.choice(population, size=n_sample)\n",
    "sample_avg = np.mean(sample)\n",
    "print(f\"Average from sample of {n_sample}: {sample_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Experiment: Draw Larger and Larger Samples === #\n",
    "\n",
    "# Max number of samples:\n",
    "k = 5000\n",
    "sample_avg = np.zeros(k)\n",
    "\n",
    "# Begin with 1 sample and increase incrementally:\n",
    "for n in range(k):\n",
    "    random_ind = np.floor(np.random.rand(n + 1) * n_pop)\n",
    "    sample_avg[n] = np.mean(population[random_ind.astype(int)])\n",
    "\n",
    "# Plot the sample averages and the\n",
    "#  expected value as a red line:\n",
    "\n",
    "# plt.plot(sample_avg, 'k')\n",
    "plt.plot(sample_avg, 's', color=\"k\", ms=0.9)\n",
    "plt.plot([1, k], [exp_val, exp_val], \"r\", lw=3)\n",
    "\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.ylim([exp_val - 1, exp_val + 1])\n",
    "plt.legend((\"Sample Average\", \"Expected Value\"))\n",
    "\n",
    "# === Take Note === #\n",
    "\n",
    "# The random sample averages get closer\n",
    "# - But they never really converge to the expected value.\n",
    "# - The variance gets smaller as the sample size increases.\n",
    "# We're still not quite dealing with the law of large numbers\n",
    "# - But we're going in the right direction.\n",
    "# The law of large numbers tells us that\n",
    "# - When we average **ALL** of the black datapoints together...\n",
    "# - We'll get the true **POPULATION PARAMETER** very quickly\n",
    "\n",
    "# Check it out, we're off by just 1/10000:\n",
    "print(np.mean(sample_avg))\n",
    "\n",
    "# We see that the mean of the sample averages\n",
    "#  coverges to the population estimate quickly.\n",
    "# We're getting fairly close to the expected value,\n",
    "#  but not nearly as close as the above average of\n",
    "#  *all* the sample averages:\n",
    "print(np.mean(sample_avg[:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate population data with known mean:\n",
    "population_n = 1000000\n",
    "population = np.random.randn(population_n)\n",
    "# De-mean (enforce as 0 mean):\n",
    "population = population - np.mean(population)\n",
    "\n",
    "# Get means of samples, sample size 30.\n",
    "# Previous version took larger and larger\n",
    "#  samples:\n",
    "sample_size = 30\n",
    "# 500 repetitions of 30 random samples:\n",
    "n_experiments = 500\n",
    "sample_means = np.zeros(n_experiments)\n",
    "\n",
    "for exp_i in range(n_experiments):\n",
    "    # Get sample and compute its mean:\n",
    "    sample_index = np.random.randint(0, population_n, sample_size)\n",
    "    sample_means[exp_i] = np.mean(population[sample_index])\n",
    "\n",
    "# Show the results:\n",
    "fig, ax = plt.subplots(2, 1, figsize=(7, 9))\n",
    "\n",
    "# Since the sample size is staying exactly the same,\n",
    "#  the variance around the mean remains the same.\n",
    "# They're all *INDEPENDENT EXPERIMENTS*:\n",
    "ax[0].plot(sample_means, 's-')\n",
    "ax[0].plot([0, n_experiments], [np.mean(population), np.mean(population)], 'r', lw=3)\n",
    "ax[0].set_xlabel(\"Experiment Number\")\n",
    "ax[0].set_ylabel(\"Mean Value\")\n",
    "ax[0].legend((\"Sample Means\", \"Population Mean\"))\n",
    "\n",
    "\n",
    "# The law of large numbers tells us that the more\n",
    "#  of the samples we put together, the closer we\n",
    "#  get to the population mean.\n",
    "# We compute the *CUMULATIVE AVERAGE*, implemented\n",
    "#  as the cumulative_sum/incresing_ind.\n",
    "# The increasing index goes from 1 to n_experiments.\n",
    "# We're computing all the sums and dividing by n.\n",
    "# We still retain some bias, but we're getting closer\n",
    "#  and closer to the population mean than with ax[0],\n",
    "#  much faster than any individual point in ax[0].\n",
    "# Look at y-axis scaling to see how small the discrepencies\n",
    "#  are getting, an *ORDER OF MAGNITUDE* difference between\n",
    "#  the plots.\n",
    "ax[1].plot(np.cumsum(sample_means) / np.arange(1, n_experiments + 1), 's-')\n",
    "ax[1].plot([0, n_experiments], [np.mean(population), np.mean(population)], 'r', lw=3)\n",
    "ax[1].set_xlabel(\"Experiment Number\")\n",
    "ax[1].set_ylabel(\"Mean Value\")\n",
    "ax[1].legend((\"Sample Means\", \"Population Mean\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LINEAR MIXTURES\n",
    "\n",
    "x = np.linspace(0, 6 * np.pi, 10001)\n",
    "s = np.sin(x)\n",
    "# Uniformly distributed numbers from -1 to +1,\n",
    "#  same y-axis scale as s:\n",
    "u = 2 * np.random.rand(len(x)) - 1\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10, 6))\n",
    "\n",
    "ax[0, 0].plot(x, s, 'b')\n",
    "ax[0, 0].set_title(\"Signal\")\n",
    "ax[1, 0].hist(s, 40)\n",
    "ax[1, 0].set_title(\"Distribution\")\n",
    "\n",
    "ax[0, 1].plot(x, u, 'm')\n",
    "ax[0, 1].set_title(\"Signal\")\n",
    "ax[1, 1].hist(u, 40)\n",
    "ax[1, 1].set_title(\"Distribution\")\n",
    "\n",
    "ax[0, 2].plot(x, s + u, 'k')\n",
    "ax[0, 2].set_title(\"Signal\")\n",
    "ax[1, 2].hist(s + u, 40)\n",
    "ax[1, 2].set_title(\"Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "dist1 = np.arange(1, N + 1)\n",
    "dist2 = np.arange(1, N + 1)\n",
    "\n",
    "# Method 1:\n",
    "# avgs = np.zeros(len(dist1) ** 2)\n",
    "# curr = 0\n",
    "# for i in range(len(dist1)):\n",
    "#     for j in range(len(dist2)):\n",
    "#         avg = (dist1[i] + dist2[j]) / 2\n",
    "#         avgs[curr + j] = avg\n",
    "#     curr += len(dist1)\n",
    "\n",
    "# Method 2 using built-in function:\n",
    "avgs = np.add.outer(dist1, dist2) / 2\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Plot the detailed landscape:\n",
    "for i in range(N):\n",
    "    rand_indices = np.random.randint(0, N, N // 50)\n",
    "    y, x = np.histogram(avgs[rand_indices].flatten(), bins=np.random.randint(25, 50))\n",
    "    mids = (x[:-1] + x[1:]) / 2\n",
    "    plt.plot(\n",
    "        mids,\n",
    "        y + 50 + i * 10,\n",
    "        'd',\n",
    "        ms=np.random.randint(1, 8),\n",
    "        color=np.random.choice(['crimson', 'tomato', 'limegreen', 'dodgerblue', 'chartreuse']),\n",
    "    )\n",
    "\n",
    "# Plot the sky:\n",
    "for i in range(N):\n",
    "    y, x = np.histogram(avgs.flatten(), bins=np.random.randint(25, 50))\n",
    "    mids = (x[:-1] + x[1:]) / 2\n",
    "    plt.plot(\n",
    "        mids,\n",
    "        y + 50 + i * 10,\n",
    "        '-',\n",
    "        color=(abs(239 - (i * 2)) / 255, abs(165 - (i * 3)) / 255, abs(25 + (i * 1)) / 255),\n",
    "        lw=95,\n",
    "    )\n",
    "\n",
    "# Plot the mountain:\n",
    "plt.hist(avgs.flatten(), 40, color='sienna')\n",
    "\n",
    "# Plot the water:\n",
    "a, b = 0, 100\n",
    "for i in range(N // 10):\n",
    "    plt.plot(\n",
    "        avgs[a:b],\n",
    "        '-',\n",
    "        color=(((134 - (i * 14)) / 255, (206 - (i * 20)) / 255, (250 - (i * 10)) / 255)),\n",
    "    )\n",
    "    a += N // 10\n",
    "    b += N // 10\n",
    "\n",
    "plt.xlim(5, 95)\n",
    "plt.ylim(50, 500)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.title(\"Central Limit Mountain\", size=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Code:_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 style=\"font-family: Courier; font-weight: 700; text-align: center; color: ivory; text-shadow: orangered 0.05rem 0.05rem 0.65rem, goldenrod 0.05rem -0.05rem 0.65rem, dodgerblue -0.05rem -0.05rem 0.65rem; magenta -0.05rem 0.05rem 0.65rem\">\n",
    "\n",
    "All stable processes we shall predict.\n",
    "<br>\n",
    "\n",
    "<font size=4>_All unstable processes we shall control._</font>\n",
    "\n",
    "<font size=2>_JvN_</font>\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px #5EDC1F; width: 75%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px magenta; width: 65%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px gold; width: 55%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2>\n",
    "\n",
    "_Andrew Blais, Boston, Massachusetts_\n",
    "\n",
    "GitHub: https://github.com/andrewblais\n",
    "\n",
    "Website/Python Web Development Portfolio: https://www.andrewblais.dev/\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=1>\n",
    "\n",
    "```python\n",
    "# Tiny Python code block\n",
    "```\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2>\n",
    "\n",
    "```python\n",
    "# Small Python code block\n",
    "```\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 style=\"color: orangered; font-weight: 500; text-shadow: goldenrod 0.05rem -0.05rem 0.65rem;\">\n",
    "\n",
    "```py\n",
    "# Large Python code block\n",
    "```\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Python Code Display: Two Columns_**\n",
    "\n",
    "<font size=6 style=\"font-size: .7rem; display: flex; flex-wrap: no-wrap; justify-content: center;\">\n",
    "\n",
    "<div>\n",
    "\n",
    "```python\n",
    "print(\"Frogs are cool\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "```python\n",
    "print(\"Frogs are great\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 3px groove #5EDC1F; border-radius: 5px; width: fit-content; text-align: center; padding: 0.35em 0.75em;\">\n",
    "  <span style=\"font-size: 15px; font-weight: bold; color: #5EDC1F;\">\n",
    "    RESUME AT 03:17\n",
    "  </span>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
