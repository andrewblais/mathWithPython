{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_Computing the Determinant of 'Singular' Matrices_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Goals:_**\n",
    "\n",
    "-   Using a `for` loop, iterate over each lambda value in `lambdas = np.linspace(0, .1, 30)`.\n",
    "\n",
    "-   For each value of $\\lambda$:\n",
    "\n",
    "    -   Generate a random square matrix `S` of dimensions `20x20`.\n",
    "\n",
    "    -   Impose linear dependence to make `S` singular, where we expect determinant to be `0`.\n",
    "\n",
    "    -   Scalar-multiply the identity matrix by that value of $\\lambda$, giving us `ID_LAM`.\n",
    "\n",
    "    -   Shift `S` by adding `ID_LAM`, giving us `S_SHIFT`.\n",
    "\n",
    "    -   Compute the determinant of `S_SHIFT`.\n",
    "\n",
    "    -   Repeat this process `1000` times for each $\\lambda$ and calculate the average determinant to ensure robustness against fluctuations around `0`.\n",
    "\n",
    "-   Plot the average determinants (y-axis) against $\\lambda$ (x-axis).\n",
    "\n",
    "-   What do we notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python Jupyter notebook extrapolates from an exercise in Mike X. Cohen's Linear Algebra course on Udemy.\n",
    "\n",
    "-   Udemy course: https://www.udemy.com/course/linear-algebra-theory-and-implementation\n",
    "\n",
    "-   Professor Cohen's website: https://www.mikexcohen.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Code:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of lambdas (shifters) to use:\n",
    "num_lambdas = 30\n",
    "\n",
    "# Number of matrices to test, then average,\n",
    "#  for each lambda:\n",
    "mats_to_avg = 1000\n",
    "\n",
    "# Square matrix rows/cols:\n",
    "mat_dim = 20\n",
    "\n",
    "# Final array of average determinants accumulated\n",
    "#  from each round of tests:\n",
    "avg_dets = np.zeros(num_lambdas)\n",
    "\n",
    "# Instantiate array to populate determinants,\n",
    "#  which we'll take the average of, to use and\n",
    "#  overwrite for each round of tests:\n",
    "det_lam = np.zeros(mats_to_avg)\n",
    "\n",
    "# Array of shift/lambda values to iterate over:\n",
    "lambdas = np.linspace(0, 0.1, num_lambdas)\n",
    "\n",
    "# Iterate over lambdas:\n",
    "for li in range(len(lambdas)):\n",
    "    # For each lambda, run multiple tests:\n",
    "    for ti in range(mats_to_avg):\n",
    "        # Instantiate matrix for each subtest:\n",
    "        S = np.random.randn(mat_dim, mat_dim)\n",
    "        # Swap two rows:\n",
    "        S[[3], :] = S[[13], :]\n",
    "        # Get sum of matrix with the Identity\n",
    "        #  matrix, then multiply by lambda scalar:\n",
    "        ID_LAM = lambdas[li] * np.eye((mat_dim))\n",
    "        S_SHIFT = S + ID_LAM\n",
    "        # Add absolute value of determinant to temp\n",
    "        #  array for averaging:\n",
    "        det_lam[ti] = abs(np.linalg.det(S_SHIFT))\n",
    "    # Take the average and save this value\n",
    "    #  for plotting:\n",
    "    avg_dets[li] = np.mean(det_lam)\n",
    "\n",
    "# Plot the lambdas against the average magnitudes\n",
    "#  of the determinants:\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.plot(\n",
    "    lambdas,\n",
    "    avg_dets,\n",
    "    \"o-\",\n",
    "    color=\"navy\",\n",
    "    markersize=9,\n",
    "    markerfacecolor=\"orangered\",\n",
    "    markeredgewidth=1.35,\n",
    "    linewidth=3,\n",
    ")\n",
    "plt.xlabel(\"$\\\\lambda$\", size=16)\n",
    "plt.ylabel(\"'Determinants' after Shifting by $ID * \\\\lambda$\", size=16)\n",
    "plt.title(\"$\\\\lambda$ vs. 'Determinants' of a 'Singular' Matrix\\n\", size=20)\n",
    "\n",
    "plt.grid(\"gainsboro\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Analysis:_**\n",
    "\n",
    "-   Shifting a matrix by the identity matrix has no effect on the matrix rank or determinant.\n",
    "\n",
    "-   When including $\\lambda$ in our calculations, the (average) determinants should remain `0` since we've force linear dependence in our matrices.\n",
    "\n",
    "-   But as $\\lambda$ increases and we shift the matrices further, the computed determinant grows larger and larger, even though we've curated singular matrices.\n",
    "\n",
    "-   Small changes in $\\lambda$ have dramatically affected the determinant.\n",
    "\n",
    "-   The computed determinant via `np.linalg.det()`, is sensitive to shifts/perturbations.\n",
    "\n",
    "-   Python has only so much dataspace to hold floating point numbers, and we're noticing how this limitation affects our calculations.\n",
    "\n",
    "-   We'll need better ways to measure the determinant of (nearly) singular matrices.\n",
    "\n",
    "-   But we've also learned that we can a matrix less singular, more towards full-rank, with this technique. It will be important to learn when to employ this regularization tool.\n",
    "\n",
    "-   As my education progresses, I'll work on finding more numerically stable and reliable ways for dealing with ill-conditioned matrices and how this relates to Statistics, Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px #5EDC1F; width: 75%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px magenta; width: 65%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px gold; width: 55%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2>\n",
    "\n",
    "_Andrew Blais, Boston, Massachusetts_\n",
    "\n",
    "GitHub: https://github.com/andrewblais\n",
    "\n",
    "Website/Python Web Development Porfolio: https://www.andrewblais.dev/\n",
    "\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
