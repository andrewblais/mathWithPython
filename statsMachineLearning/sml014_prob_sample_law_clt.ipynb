{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_Probability Sampling, Law of Large Numbers, ..._**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Goal:_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 style=\"color: orangered; font-weight: 500; text-shadow: goldenrod 0.05rem -0.05rem 0.65rem;\">\n",
    "\n",
    "\"Monte Carlo Sampling\" is the same thing as randomly sampling from a population to estimate an unknown population parameter.\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Monte Carlo Sampling to estimate the average of a population distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "N = 34203\n",
    "\n",
    "couches = np.round(np.random.randn(N), 2)\n",
    "plt.plot(np.mean(couches), '.', ms=100)\n",
    "\n",
    "S = 1000\n",
    "colors = np.linspace(1, 0, S)\n",
    "sample_size = 2\n",
    "for i in range(S):\n",
    "    sample_i = np.random.choice(couches, size=sample_size)\n",
    "    plt.plot(np.mean(sample_i), '.', ms=1, color=((colors[i], colors[i], colors[i])))\n",
    "    sample_size += 10\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Creating a Distribution of Sample Estimates..._**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Scientific Question #2: Are giraffes taller than slow lorises?_**\n",
    "\n",
    "-   In an earlier lesson we wondered when we actually need Probability & Statistics.\n",
    "\n",
    "-   For a question like this, we don't need Probability Theory, we don't need inferential statistics.\n",
    "\n",
    "-   This is because the shortest giraffe will be taller than the tallest slow loris.\n",
    "\n",
    "-   Not a meaningful question, but a useful didactic tool\n",
    "\n",
    "Now we go ahead and answer it:\n",
    "\n",
    "We cannot measure the entire population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **\\_So we measure a **SAMPLE** from each group:\\_**\n",
    "\n",
    "-   Measure a small sample of giraffes vs. a small sample of slow lorises.\n",
    "\n",
    "-   Then compute the difference between these two specific samples' averages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Repeat the Process for a Different Sample:_**\n",
    "\n",
    "-   Take another random group of giraffes and another random group of slow lorises.\n",
    "\n",
    "-   Again measure the difference in their means.\n",
    "\n",
    "-   The difference from the first comparison is unlikely to be identical to the difference from the second comparision, but we expect them to be comparable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo Sampling is a fancier term for what we did in the previous lesson:\n",
    "\n",
    "-   Randomly sampling data from a distribution in order to use that randomness to estimate an unknown parameter or unknown function in that population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Take Many Samples:_**\n",
    "\n",
    "Averaging together many samples will approximate the true population mean (see lecture on _Law of Large Numbers_).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wouldn't trust the average height of a population based on one individual.\n",
    "\n",
    "So we measure a lot of people and average together with the key underlying assumption:\n",
    "\n",
    "-   Variability is both positive and negative.\n",
    "\n",
    "-   There's variability both _above_ and _below_ the average height.\n",
    "\n",
    "-   By averaging together we get a convergence to the true population mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the theoretical normal appears almost flat.\n",
    "\n",
    "It's so finely discretized relative to the sample distribution, which is only discretized into `10` or so bins.\n",
    "\n",
    "The theoretical is discretized into `10101` bins.\n",
    "\n",
    "These distributions can be tricky to normalize in a way that facilitates a visual comparison in the same plot.\n",
    "\n",
    "Commenting out this normalization and ensuring `hist(density=True)` creates a plot where both distributions are normalized to a good range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# A 'theoretical' normal distribution...\n",
    "#  not a true theoretical normal distribution\n",
    "#  as we're discretizing on a computer. 10101\n",
    "#  points is a good discretization rate, though:\n",
    "x = np.linspace(-5, 5, 10101)\n",
    "theo_norm_dist = stats.norm.pdf(x)\n",
    "\n",
    "# Compare against histogram, an empirical\n",
    "#  distribution of sample data randomly\n",
    "#  drawn from normal distribution:\n",
    "num_samples = 40\n",
    "# Initialize:\n",
    "sample_data = np.zeros(num_samples)\n",
    "\n",
    "# Run the experiment. Using for loop to clarify that\n",
    "#  this is an experiment we're running. Adding a random\n",
    "#  number for each iteration without consideration for\n",
    "#  the other random numbers in the experiment:\n",
    "for exp_i in range(num_samples):\n",
    "    sample_data[exp_i] = np.random.randn()\n",
    "\n",
    "# Plot the results:\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.hist(sample_data, density=True, label=\"Empirical/Sample Distribution\")\n",
    "plt.plot(x, theo_norm_dist, 'r', lw=3, label=\"Theoretical/Population Distribution\")\n",
    "plt.xlabel(\"Data Values\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 10101)\n",
    "theo_norm_dist = stats.norm.pdf(x)\n",
    "\n",
    "# Normalize to pdf:\n",
    "theo_norm_dist = theo_norm_dist * np.mean(np.diff(x))\n",
    "\n",
    "num_samples = 400\n",
    "sample_data = np.zeros(num_samples)\n",
    "\n",
    "for exp_i in range(num_samples):\n",
    "    sample_data[exp_i] = np.random.randn()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.hist(sample_data, density=True, label=\"Empirical/Sample Distribution\")\n",
    "plt.plot(x, theo_norm_dist, 'r', lw=3, label=\"Theoretical/Population Distribution\")\n",
    "plt.xlabel(\"Data Values\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the theoretical normal appears almost flat.\n",
    "\n",
    "It's so finely discretized relative to the sample distribution, which is only discretized into `10` or so bins.\n",
    "\n",
    "The theoretical is discretized into `10101` bins.\n",
    "\n",
    "These distributions can be tricky to normalize in a way that facilitates a visual comparison in the same plot.\n",
    "\n",
    "Commenting out this normalization and ensuring `hist(density=True)` creates a plot where both distributions are normalized to a good range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 10101)\n",
    "theo_norm_dist = stats.norm.pdf(x)\n",
    "\n",
    "# Normalize to pdf:\n",
    "# theo_norm_dist = theo_norm_dist * np.mean(np.diff(x))\n",
    "\n",
    "num_samples = 400\n",
    "sample_data = np.zeros(num_samples)\n",
    "\n",
    "for exp_i in range(num_samples):\n",
    "    sample_data[exp_i] = np.random.randn()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.hist(sample_data, density=True, label=\"Empirical/Sample Distribution\")\n",
    "plt.plot(x, theo_norm_dist, 'r', lw=3, label=\"Theoretical/Population Distribution\")\n",
    "plt.xlabel(\"Data Values\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the mean of samples of a known distribution...\n",
    "\n",
    "# # Generate population data with known mean...\n",
    "# Imagine this is all the people in Amsterdam:\n",
    "population_n = 1000000\n",
    "# This is our ENTIRE population. Imagine we're asking\n",
    "#  each person what they think about rain. Positive\n",
    "#  means you like rain, negative you don't like rain:\n",
    "population = np.random.randn(population_n)\n",
    "\n",
    "# Subtract mean to force average to 0, so this\n",
    "#  means population average is neutral feelings\n",
    "#  about rain:\n",
    "population = population - np.mean(population)\n",
    "\n",
    "# Draw a random sample of 30. Asking 30 random Amsterdam\n",
    "#  residents what they think about rain:\n",
    "sample_size = 30\n",
    "\n",
    "# The we take the average of this sample. We gather the\n",
    "#  indices to select from the population:\n",
    "sample_indices = np.random.randint(0, population_n, sample_size)\n",
    "sample_mean = np.mean(population[sample_indices])\n",
    "\n",
    "# # How does the sample mean compare to the population mean?\n",
    "print(np.round(np.mean(population), 13))\n",
    "print(np.round(sample_mean, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = np.arange(30, 1000)\n",
    "sample_means = np.zeros(len(sample_sizes))\n",
    "\n",
    "for samp_i in range(len(sample_sizes)):\n",
    "    # Nearly the same code as before:\n",
    "    sample_index = np.random.randint(0, population_n, sample_sizes[samp_i])\n",
    "    sample_means[samp_i] = np.mean(population[sample_index])\n",
    "\n",
    "# Show the results:\n",
    "plt.plot(sample_sizes, sample_means, 's-')\n",
    "# Constant:\n",
    "plt.plot(sample_sizes[[0, -1]], [np.mean(population), np.mean(population)], 'r', lw=3)\n",
    "plt.xlabel(\"Sample Size\")\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.legend((\"Sample Means\", \"Population Mean\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Expected Value vs. Average: Example_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine an 'illegal' (weighted) die, where the chances of getting each of the six sides aren't equal:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Side 1: $p = \\frac{1}{4}$**\n",
    "\n",
    "##### **Side 2: $p = \\frac{1}{4}$**\n",
    "\n",
    "##### **Side 3: $p = \\frac{1}{8}$**\n",
    "\n",
    "##### **Side 4: $p = \\frac{1}{8}$**\n",
    "\n",
    "##### **Side 5: $p = \\frac{1}{8}$**\n",
    "\n",
    "##### **Side 6: $p = \\frac{1}{8}$**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Quick Sanity Check:_\n",
    "\n",
    "-   Do the possible values all add up to $1$?\n",
    "\n",
    "-   Are the possibilities _exclusive_?\n",
    "\n",
    "-   We're excluding the possibility of the die landing on an edge.\n",
    "\n",
    "Now we can talk seriously about the Probability Mass Distribution of this die...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_What is the Expected Value of this die?_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Reminder of formula for expected value:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\Large\n",
    "    \\mathbf{E}[X]\n",
    "    \\; = \\;\n",
    "    \\sum_{i = 1}^n\n",
    "    \\;\n",
    "    x_i \\, p_i\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\Large\n",
    "    \\begin{matrix}\n",
    "        \\text{.} \\; p = \\frac{1}{4} & &\n",
    "        \\text{..} \\; p = \\frac{1}{4} \\\\ \\\\\n",
    "        \\text{:.} \\; p = \\frac{1}{8} & &\n",
    "        \\text{::} \\; p = \\frac{1}{8} \\\\ \\\\\n",
    "        \\text{::.} \\; p = \\frac{1}{8} & &\n",
    "        \\text{:::} \\; p = \\frac{1}{8}\n",
    "    \\end{matrix}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_anb:_\n",
    "\n",
    "I think it's exactly the same as the fractions.\n",
    "\n",
    "_e.g.,_ `1` has a `1/4` expected value, etc...\n",
    "\n",
    "Multiply $p_i$ times $x_i$. But $x_i$ isn't the number you rolled, rather the width of its bin, `1`.\n",
    "\n",
    "Or is the question asking what is the most likely result?\n",
    "\n",
    "I don't know, in that case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Mike:_\n",
    "\n",
    "We compute this by literally writing out the formula:\n",
    "\n",
    "$\n",
    "\\Large\n",
    "    \\begin{aligned}\n",
    "        & \\mathbf{E}[X] \\; = \\; \\sum_{i = 1}^n \\; x_i \\, p_i\n",
    "        \\\\ \\\\\n",
    "        & = 1p_1 + 2p_2 + 3p_3 + 4p_4 + 5p_5 + 6p_6\n",
    "        \\\\ \\\\\n",
    "        & = \\frac{1}{4} + \\frac{2}{4} + \\frac{3}{8} + \\frac{4}{8} + \\frac{5}{8} + \\frac{6}{8}\n",
    "        \\\\ \\\\\n",
    "        & = 3\n",
    "    \\end{aligned}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_anb:_\n",
    "\n",
    "-   I didn't realize you could plug the actual values in as $x_i$.\n",
    "\n",
    "-   For some reason I was thinking that's the index.\n",
    "\n",
    "-   I'd lost the thread on this concept, but it's clicking now...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't actually collect a single data point to compute this Expected Value.\n",
    "\n",
    "We can compute this expected value knowing **ALL THE PROBABILITIES OF ALL THE POSSIBILITIES**.\n",
    "\n",
    "So no data was required to compute the expected value...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Computing the Average:_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In contrast** with computing the average:\n",
    "\n",
    "-   To compute the average of a sample, we need sample data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine `8` random rolls of the loaded die:\n",
    "\n",
    "$1 \\qquad 3 \\qquad 4 \\qquad 4 \\qquad 4 \\qquad 3 \\qquad 2 \\qquad 5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average of this sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_anb:_\n",
    "\n",
    "-   `(1 + 3 + 4 + 4 + 4 + 3 + 2 + 5) / 8`\n",
    "\n",
    "-   `26 / 8`\n",
    "\n",
    "-   `3 2/8`\n",
    "\n",
    "-   `3 1/4`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct.\n",
    "\n",
    "`3.25` is the **Average** of the sample.\n",
    "\n",
    "The **Expected Value** is `3`.\n",
    "\n",
    "The average can vary from sample to sample.\n",
    "\n",
    "Would the average of many averages of many samples converge to the expected value?\n",
    "\n",
    "No, they're not necessarily the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the expected value requires no data, not a single data point.\n",
    "\n",
    "Whereas we do need data to compute the average.\n",
    "\n",
    "_anb:_ I don't understand why that means the average of many samples' averages won't converge toward the expected value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 style=\"color: goldenrod; font-weight: 500;\">\n",
    "\n",
    "$\\textcolor{dodgerblue}{A}$ and $\\textcolor{darkturquoise}{B}$ are independent when knowing\n",
    "<br>\n",
    "$\\textcolor{ivory}{P}(\\textcolor{dodgerblue}{A})$ provides no information about $\\textcolor{ivory}{P}(\\textcolor{darkturquoise}{B})$\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\huge\n",
    "    P (\\textcolor{dodgerblue}{A} \\cap \\textcolor{darkturquoise}{B})\n",
    "    \\; = \\;\n",
    "    P (\\textcolor{dodgerblue}{A}) \\ P (\\textcolor{darkturquoise}{B})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The probability of $A \\cap B$ ('$A$ intersection with $B$'), if the two events are independent of each other is equal to the probability of $A$ times the probability of $B$\"\n",
    "\n",
    "The probability of their intersection is equal to the product of the two probabilities on their own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px #5EDC1F; width: 70%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $A$ and $B$ are **NOT** independent (if $A$ and $B$ are dependent), then the definition of $A$ intersect $B$ changes:\n",
    "\n",
    "-   The probability of A given B times the probability of B...\n",
    "\n",
    "-   Reworking the original equation a bit.\n",
    "\n",
    "-   More on this later...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GENERATE TWO LONG-SPIKE TIME SERIES.\n",
    "# #  More like 'plateaus', 0 could correspond\n",
    "# #  to sunny days, 1 to rainy days...\n",
    "\n",
    "N = 10000\n",
    "# a.u. (arbitrary units) but must be even num:\n",
    "spike_dur = 10\n",
    "# In proportion to num points:\n",
    "spike_num_a = 0.01\n",
    "spike_num_b = 0.05\n",
    "\n",
    "# Initialize to zeros:\n",
    "spike_ts1 = np.zeros(N)\n",
    "spike_ts2 = np.zeros(N)\n",
    "\n",
    "# # Populate time series 1. Generate a bunch of\n",
    "# #  random ints to be the 'spike centers'.\n",
    "spike_times_1 = np.random.randint(0, N, int(N * spike_num_a))\n",
    "\n",
    "# Flex out spikes (loops per spike). Loop through all\n",
    "#  the ints and specify that from the spike onset (center)\n",
    "#  time +- spike_dur/2 gets turned to 1's:\n",
    "for spike_i in range(len(spike_times_1)):\n",
    "\n",
    "    # Find boundaries. Think carefully about these two lines.\n",
    "    #  They account for places where we might have spikes exactly\n",
    "    #  at the boundaries. Prevents indexing error if spike center\n",
    "    #  is really close to beginning or end of time series:\n",
    "    bound_pre = int(max(0, spike_times_1[spike_i] - spike_dur / 2))\n",
    "    bound_post = int(min(N, spike_times_1[spike_i] + spike_dur / 2))\n",
    "\n",
    "    # Fill in with ones:\n",
    "    spike_ts1[bound_pre:bound_post] = 1\n",
    "\n",
    "# # Repeat for time series 2:\n",
    "spike_times_2 = np.random.randint(0, N, int(N * spike_num_b))\n",
    "# Alternatively, induce strong conditional probability:\n",
    "# spike_times_2[:len(spike_times_1)] = spike_times_1\n",
    "\n",
    "# Flex out spikes (loops per spike):\n",
    "for spike_i in range(len(spike_times_2)):\n",
    "\n",
    "    # Find boundaries:\n",
    "    bound_pre = int(max(0, spike_times_2[spike_i] - spike_dur / 2))\n",
    "    bound_post = int(min(N, spike_times_2[spike_i] + spike_dur / 2))\n",
    "\n",
    "    # Fill in with ones:\n",
    "    spike_ts2[bound_pre:bound_post] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(N), spike_ts1, range(N), spike_ts2)\n",
    "plt.plot(range(N), spike_ts1, lw=3, c='goldenrod')\n",
    "plt.plot(range(N), spike_ts2, ls='--', c='dodgerblue')\n",
    "plt.ylim([0, 1.2])\n",
    "# Zoom in:\n",
    "plt.xlim([2000, 2500])\n",
    "# plt.xlim([2000, 2250])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities. Two ways of computing the\n",
    "#  average:\n",
    "prob_a = sum(spike_ts1 == 1) / N\n",
    "# Since the data is simplified to 0 or\n",
    "#  1, we can simply take the mean:\n",
    "prob_b = np.mean(spike_ts2)\n",
    "\n",
    "# Joint probability. spike_ts1 + spike_ts2 vals\n",
    "#  will be either 0, 1 (spike in one or other\n",
    "#  channel) or 2 (spike in both channels):\n",
    "prob_ab = np.mean(spike_ts1 + spike_ts2 == 2)\n",
    "\n",
    "print(prob_a, prob_b, prob_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(A|B):\n",
    "p_a_given_b = prob_ab / prob_b\n",
    "\n",
    "# P(B|A), scale by the probability\n",
    "#  of a:\n",
    "p_b_given_a = prob_ab / prob_a\n",
    "\n",
    "# Print a report:\n",
    "print(\"P(A) = %g\" % prob_a)\n",
    "print(\"P(A|B) = %g\" % p_a_given_b)\n",
    "print(\"P(B) = %g\" % prob_b)\n",
    "print(\"P(B|A) = %g\" % p_b_given_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "spike_dur = 10\n",
    "spike_num_a = 0.01\n",
    "spike_num_b = 0.05\n",
    "\n",
    "spike_ts1 = np.zeros(N)\n",
    "spike_ts2 = np.zeros(N)\n",
    "\n",
    "spike_times_1 = np.random.randint(0, N, int(N * spike_num_a))\n",
    "for spike_i in range(len(spike_times_1)):\n",
    "    bound_pre = int(max(0, spike_times_1[spike_i] - spike_dur / 2))\n",
    "    bound_post = int(min(N, spike_times_1[spike_i] + spike_dur / 2))\n",
    "    spike_ts1[bound_pre:bound_post] = 1\n",
    "\n",
    "spike_times_2 = np.random.randint(0, N, int(N * spike_num_b))\n",
    "spike_times_2[: len(spike_times_1)] = spike_times_1\n",
    "for spike_i in range(len(spike_times_2)):\n",
    "    bound_pre = int(max(0, spike_times_2[spike_i] - spike_dur / 2))\n",
    "    bound_post = int(min(N, spike_times_2[spike_i] + spike_dur / 2))\n",
    "    spike_ts2[bound_pre:bound_post] = 1\n",
    "\n",
    "prob_a = sum(spike_ts1 == 1) / N\n",
    "prob_b = np.mean(spike_ts2)\n",
    "prob_ab = np.mean(spike_ts1 + spike_ts2 == 2)\n",
    "\n",
    "print(prob_a, prob_b, prob_ab)\n",
    "\n",
    "p_a_given_b = prob_ab / prob_b\n",
    "p_b_given_a = prob_ab / prob_a\n",
    "\n",
    "print(\"P(A) = %g\" % prob_a)\n",
    "print(\"P(A|B) = %g\" % p_a_given_b)\n",
    "print(\"P(B) = %g\" % prob_b)\n",
    "print(\"P(B|A) = %g\" % p_b_given_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret and read probabilities off a Tree Diagram:\n",
    "\n",
    "-   Start from the beginning\n",
    "\n",
    "-   Move along each branch as appropriate\n",
    "\n",
    "-   If starting from '`A`', or answering a question about a conditional probability, just start immediately from whichever node is the conditional.\n",
    "\n",
    "-   To find the probabilities in total, start from the beginning and go through each probability, multiplying all the branches as you go through them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 style=\"color: dodgerblue; font-weight: 500; text-shadow: goldenrod 0.05rem -0.05rem 0.65rem; text-align: center;\">\n",
    "\n",
    "As the number of experiment repetitions increases, the average of the sample means better approximates the population mean.\n",
    "\n",
    "</font>\n",
    "\n",
    "<font size=2>\n",
    "\n",
    "_We typically don't know the true population mean. If we did, we wouldn't have to do the experiment._\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\huge\n",
    "    \\lim_{n \\to \\infty} \\; P(\\lvert \\bar{x}_n - \\mu \\rvert > \\epsilon) = 0\n",
    "\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anb:\n",
    "import numpy as np\n",
    "\n",
    "machine_epsilon_float64 = np.finfo(float).eps\n",
    "print(\"machine_epsilon_float64:\", machine_epsilon_float64)\n",
    "machine_epsilon_float32 = np.finfo(np.float32).eps\n",
    "print(\"machine_epsilon_float32:\", machine_epsilon_float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Import Libraries === #\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Example with Rolling a Die === #\n",
    "\n",
    "# Die probabilities (weighted, loaded, 'unfair'):\n",
    "face_1 = 2 / 8\n",
    "face_2 = 2 / 8\n",
    "face_3 = 1 / 8\n",
    "face_4 = 1 / 8\n",
    "face_5 = 1 / 8\n",
    "face_6 = 1 / 8\n",
    "\n",
    "# If truly a probability mass function, the\n",
    "#  probabilities should sum to 1, confirm:\n",
    "sum_probs = face_1 + face_2 + face_3 + face_4 + face_5 + face_6\n",
    "# print(\"Sum of probabilities of weighted die:\", sum_probs)  # 1.0\n",
    "\n",
    "# Expected value. Sum of (value * probability of\n",
    "#  getting that value). Rolling a 1 on the\n",
    "#  die * a probability of getting that 1, etc...:\n",
    "exp_val = 1 * face_1 + 2 * face_2 + 3 * face_3 + 4 * face_4 + 5 * face_5 + 6 * face_6\n",
    "print(\"Expected value of the weighted die:\", exp_val)  # 3.0\n",
    "\n",
    "# Generate \"population\". Generating a 'seed' of\n",
    "#  a population based on their probabilities of\n",
    "#  occurences. Rolling a 1 or 2 are each twice\n",
    "#  more likely than 3, 4, 5 or 6, so we take the\n",
    "#  seed vector and keep concatenating it on\n",
    "#  itself\n",
    "population = [1, 1, 2, 2, 3, 4, 5, 6]\n",
    "for _ in range(20):\n",
    "    population = np.hstack((population, population))\n",
    "\n",
    "\n",
    "n_pop = len(population)\n",
    "# Over 8,000,000 die rolls:\n",
    "# print(\"Number of elements in the population:\", n_pop)  # 8388608\n",
    "\n",
    "# Draw random sample of 8 rolls from population,\n",
    "#  just like randomly sampling from our population\n",
    "#  8 times:\n",
    "n_sample = 8\n",
    "sample = np.random.choice(population, size=n_sample)\n",
    "sample_avg = np.mean(sample)\n",
    "print(f\"Average from sample of {n_sample}: {sample_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Experiment: Draw Larger and Larger Samples === #\n",
    "\n",
    "# Max number of samples:\n",
    "k = 5000\n",
    "sample_avg = np.zeros(k)\n",
    "\n",
    "# Begin with 1 sample and increase incrementally:\n",
    "for n in range(k):\n",
    "    random_ind = np.floor(np.random.rand(n + 1) * n_pop)\n",
    "    sample_avg[n] = np.mean(population[random_ind.astype(int)])\n",
    "\n",
    "# Plot the sample averages and the\n",
    "#  expected value as a red line:\n",
    "\n",
    "# plt.plot(sample_avg, 'k')\n",
    "plt.plot(sample_avg, 's', color=\"k\", ms=0.9)\n",
    "plt.plot([1, k], [exp_val, exp_val], \"r\", lw=3)\n",
    "\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.ylim([exp_val - 1, exp_val + 1])\n",
    "plt.legend((\"Sample Average\", \"Expected Value\"))\n",
    "\n",
    "# === Take Note === #\n",
    "\n",
    "# The random sample averages get closer\n",
    "# - But they never really converge to the expected value.\n",
    "# - The variance gets smaller as the sample size increases.\n",
    "# We're still not quite dealing with the law of large numbers\n",
    "# - But we're going in the right direction.\n",
    "# The law of large numbers tells us that\n",
    "# - When we average **ALL** of the black datapoints together...\n",
    "# - We'll get the true **POPULATION PARAMETER** very quickly\n",
    "\n",
    "# Check it out, we're off by just 1/10000:\n",
    "print(np.mean(sample_avg))\n",
    "\n",
    "# We see that the mean of the sample averages\n",
    "#  coverges to the population estimate quickly.\n",
    "# We're getting fairly close to the expected value,\n",
    "#  but not nearly as close as the above average of\n",
    "#  *all* the sample averages:\n",
    "print(np.mean(sample_avg[:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate population data with known mean:\n",
    "population_n = 1000000\n",
    "population = np.random.randn(population_n)\n",
    "# De-mean (enforce as 0 mean):\n",
    "population = population - np.mean(population)\n",
    "\n",
    "# Get means of samples, sample size 30.\n",
    "# Previous version took larger and larger\n",
    "#  samples:\n",
    "sample_size = 30\n",
    "# 500 repetitions of 30 random samples:\n",
    "n_experiments = 500\n",
    "sample_means = np.zeros(n_experiments)\n",
    "\n",
    "for exp_i in range(n_experiments):\n",
    "    # Get sample and compute its mean:\n",
    "    sample_index = np.random.randint(0, population_n, sample_size)\n",
    "    sample_means[exp_i] = np.mean(population[sample_index])\n",
    "\n",
    "# Show the results:\n",
    "fig, ax = plt.subplots(2, 1, figsize=(7, 9))\n",
    "\n",
    "# Since the sample size is staying exactly the same,\n",
    "#  the variance around the mean remains the same.\n",
    "# They're all *INDEPENDENT EXPERIMENTS*:\n",
    "ax[0].plot(sample_means, 's-')\n",
    "ax[0].plot([0, n_experiments], [np.mean(population), np.mean(population)], 'r', lw=3)\n",
    "ax[0].set_xlabel(\"Experiment Number\")\n",
    "ax[0].set_ylabel(\"Mean Value\")\n",
    "ax[0].legend((\"Sample Means\", \"Population Mean\"))\n",
    "\n",
    "\n",
    "# The law of large numbers tells us that the more\n",
    "#  of the samples we put together, the closer we\n",
    "#  get to the population mean.\n",
    "# We compute the *CUMULATIVE AVERAGE*, implemented\n",
    "#  as the cumulative_sum/incresing_ind.\n",
    "# The increasing index goes from 1 to n_experiments.\n",
    "# We're computing all the sums and dividing by n.\n",
    "# We still retain some bias, but we're getting closer\n",
    "#  and closer to the population mean than with ax[0],\n",
    "#  much faster than any individual point in ax[0].\n",
    "# Look at y-axis scaling to see how small the discrepencies\n",
    "#  are getting, an *ORDER OF MAGNITUDE* difference between\n",
    "#  the plots.\n",
    "ax[1].plot(np.cumsum(sample_means) / np.arange(1, n_experiments + 1), 's-')\n",
    "ax[1].plot([0, n_experiments], [np.mean(population), np.mean(population)], 'r', lw=3)\n",
    "ax[1].set_xlabel(\"Experiment Number\")\n",
    "ax[1].set_ylabel(\"Mean Value\")\n",
    "ax[1].legend((\"Sample Means\", \"Population Mean\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LINEAR MIXTURES\n",
    "\n",
    "x = np.linspace(0, 6 * np.pi, 10001)\n",
    "s = np.sin(x)\n",
    "# Uniformly distributed numbers from -1 to +1,\n",
    "#  same y-axis scale as s:\n",
    "u = 2 * np.random.rand(len(x)) - 1\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10, 6))\n",
    "\n",
    "ax[0, 0].plot(x, s, 'b')\n",
    "ax[0, 0].set_title(\"Signal\")\n",
    "ax[1, 0].hist(s, 40)\n",
    "ax[1, 0].set_title(\"Distribution\")\n",
    "\n",
    "ax[0, 1].plot(x, u, 'm')\n",
    "ax[0, 1].set_title(\"Signal\")\n",
    "ax[1, 1].hist(u, 40)\n",
    "ax[1, 1].set_title(\"Distribution\")\n",
    "\n",
    "ax[0, 2].plot(x, s + u, 'k')\n",
    "ax[0, 2].set_title(\"Signal\")\n",
    "ax[1, 2].hist(s + u, 40)\n",
    "ax[1, 2].set_title(\"Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "dist1 = np.arange(1, N + 1)\n",
    "dist2 = np.arange(1, N + 1)\n",
    "\n",
    "# Method 1:\n",
    "# avgs = np.zeros(len(dist1) ** 2)\n",
    "# curr = 0\n",
    "# for i in range(len(dist1)):\n",
    "#     for j in range(len(dist2)):\n",
    "#         avg = (dist1[i] + dist2[j]) / 2\n",
    "#         avgs[curr + j] = avg\n",
    "#     curr += len(dist1)\n",
    "\n",
    "# Method 2 using built-in function:\n",
    "avgs = np.add.outer(dist1, dist2) / 2\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Plot the detailed landscape:\n",
    "for i in range(N):\n",
    "    rand_indices = np.random.randint(0, N, N // 50)\n",
    "    y, x = np.histogram(avgs[rand_indices].flatten(), bins=np.random.randint(25, 50))\n",
    "    mids = (x[:-1] + x[1:]) / 2\n",
    "    plt.plot(\n",
    "        mids,\n",
    "        y + 50 + i * 10,\n",
    "        'd',\n",
    "        ms=np.random.randint(1, 8),\n",
    "        color=np.random.choice(['crimson', 'tomato', 'limegreen', 'dodgerblue', 'chartreuse']),\n",
    "    )\n",
    "\n",
    "# Plot the sky:\n",
    "for i in range(N):\n",
    "    y, x = np.histogram(avgs.flatten(), bins=np.random.randint(25, 50))\n",
    "    mids = (x[:-1] + x[1:]) / 2\n",
    "    plt.plot(\n",
    "        mids,\n",
    "        y + 50 + i * 10,\n",
    "        '-',\n",
    "        color=(abs(239 - (i * 2)) / 255, abs(165 - (i * 3)) / 255, abs(25 + (i * 1)) / 255),\n",
    "        lw=95,\n",
    "    )\n",
    "\n",
    "# Plot the mountain:\n",
    "plt.hist(avgs.flatten(), 40, color='sienna')\n",
    "\n",
    "# Plot the water:\n",
    "a, b = 0, 100\n",
    "for i in range(N // 10):\n",
    "    plt.plot(\n",
    "        avgs[a:b],\n",
    "        '-',\n",
    "        color=(((134 - (i * 14)) / 255, (206 - (i * 20)) / 255, (250 - (i * 10)) / 255)),\n",
    "    )\n",
    "    a += N // 10\n",
    "    b += N // 10\n",
    "\n",
    "plt.xlim(5, 95)\n",
    "plt.ylim(50, 500)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.title(\"Central Limit Mountain\", size=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Code:_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 style=\"font-family: Courier; font-weight: 700; text-align: center; color: ivory; text-shadow: orangered 0.05rem 0.05rem 0.65rem, goldenrod 0.05rem -0.05rem 0.65rem, dodgerblue -0.05rem -0.05rem 0.65rem; magenta -0.05rem 0.05rem 0.65rem\">\n",
    "\n",
    "All stable processes we shall predict.\n",
    "<br>\n",
    "\n",
    "<font size=4>_All unstable processes we shall control._</font>\n",
    "\n",
    "<font size=2>_JvN_</font>\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 85%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px #5EDC1F; width: 75%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px magenta; width: 65%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px gold; width: 55%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2>\n",
    "\n",
    "_Andrew Blais, Boston, Massachusetts_\n",
    "\n",
    "GitHub: https://github.com/andrewblais\n",
    "\n",
    "Website/Python Web Development Portfolio: https://www.andrewblais.dev/\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=1>\n",
    "\n",
    "```python\n",
    "# Tiny Python code block\n",
    "```\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2>\n",
    "\n",
    "```python\n",
    "# Small Python code block\n",
    "```\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 style=\"color: orangered; font-weight: 500; text-shadow: goldenrod 0.05rem -0.05rem 0.65rem;\">\n",
    "\n",
    "```py\n",
    "# Large Python code block\n",
    "```\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Python Code Display: Two Columns_**\n",
    "\n",
    "<font size=6 style=\"font-size: .7rem; display: flex; flex-wrap: no-wrap; justify-content: center;\">\n",
    "\n",
    "<div>\n",
    "\n",
    "```python\n",
    "print(\"Frogs are cool\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "```python\n",
    "print(\"Frogs are great\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 3px groove #5EDC1F; border-radius: 5px; width: fit-content; text-align: center; padding: 0.35em 0.75em;\">\n",
    "  <span style=\"font-size: 15px; font-weight: bold; color: #5EDC1F;\">\n",
    "    RESUME AT 03:17\n",
    "  </span>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
