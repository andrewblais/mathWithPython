{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_Using the Gram-Schmidt Procedure to Create an Orthogonal Matrix:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 95%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Intro:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates concepts from a coding challenge I studied in Mike X. Cohen's Linear Algebra course on Udemy.\n",
    "\n",
    "Essentially, this is my homework, which serves as a step-by-step review and a future quick-reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit Dr. Cohen's course here:\n",
    "\n",
    "-   Udemy course: https://www.udemy.com/course/linear-algebra-theory-and-implementation\n",
    "\n",
    "-   Professor Cohen's website: https://www.mikexcohen.com/\n",
    "\n",
    "This course has not only helped me learn more about Linear Algebra, but has significantly improved my coding skills.\n",
    "\n",
    "I'm still moving forward, slowly, toward the goal of contributing to the AI Safety conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 90%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Goal:_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to implement the Gram-Schmidt Procedure to transform a given matrix into orthogonal form.\n",
    "\n",
    "Compare and verify with NumPy's `np.linalg.qr()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 90%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Algebra Review:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_Creating Vector Components:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a vector to orthogonalize:\n",
    "\n",
    "$\n",
    "\\LARGE\n",
    "    \\mathbf{v}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation to get component of $\\mathbf{v}$ parallel to reference vector $\\mathbf{w}$:\n",
    "\n",
    "$\n",
    "\\LARGE\n",
    "    \\mathbf{v}_{\\parallel \\mathbf{w}} = \\frac{\\mathbf{v}^T \\mathbf{w}}{\\mathbf{w}^T \\mathbf{w}} \\mathbf{w}\n",
    "$\n",
    "\n",
    "_or:_\n",
    "\n",
    "$\n",
    "\\LARGE\n",
    "   \\mathrm{proj}_{\\mathbf{w}} \\mathbf{v} = \\frac{\\mathbf{v}^T \\mathbf{w}}{\\mathbf{w}^T \\mathbf{w}} \\mathbf{w}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract $\\mathbf{v}_{\\parallel \\mathbf{w}}$ from $\\mathbf{v}$ to get the orthogonal component:\n",
    "\n",
    "$\n",
    "\\LARGE\n",
    "    \\mathbf{v}_{\\perp \\mathbf{w}} = \\mathbf{v} - \\frac{\\mathbf{v}^T \\mathbf{w}}{\\mathbf{w}^T \\mathbf{w}} \\mathbf{w}\n",
    "$\n",
    "\n",
    "_or:_\n",
    "\n",
    "$\n",
    "\\LARGE\n",
    "    \\mathbf{v}_{\\perp \\mathbf{w}} = \\mathbf{v} - \\mathbf{v}_{\\parallel \\mathbf{w}}\n",
    "$\n",
    "\n",
    "_or simply:_\n",
    "\n",
    "$\n",
    "\\LARGE\n",
    "    \\mathbf{v}_{\\perp \\mathbf{w}} = \\mathbf{v} - \\mathrm{proj}_{\\mathbf{w}} \\mathbf{v}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Key:_\n",
    "\n",
    "$\n",
    "\\mathbf{v} \\Leftarrow \\text{vector to orthogonalize}\n",
    "$\n",
    "\n",
    "$\n",
    "\\mathbf{w} \\Leftarrow \\text{reference vector}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_The Gram-Schmidt Procedure:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes an input matrix and outputs an orthogonal matrix, all column vectors pairwise orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathrm{proj}_{\\vec{w}} \\vec{v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure ensuing columns are all pairwise orthogonal by progressing through the column vectors and applying:\n",
    "\n",
    "$$\n",
    "\\LARGE\n",
    "\\begin{gathered}\n",
    "    \\mathbf{q}_1 = \\mathbf{a}_1\n",
    "\n",
    "    \\\\ \\\\\n",
    "\n",
    "    \\mathbf{q}_2 = \\mathbf{a}_2 - \\mathrm{proj}_{\\mathbf{q}_1} \\mathbf{a}_2\n",
    "\n",
    "    \\\\ \\\\\n",
    "\n",
    "    \\mathbf{q}_3 = \\mathbf{a}_3 - \\mathrm{proj}_{\\mathbf{q}_1} \\mathbf{a}_3 - \\mathrm{proj}_{\\mathbf{q}_2} \\mathbf{a}_3\n",
    "\n",
    "    \\\\ \\\\\n",
    "\n",
    "    \\mathbf{q}_4 = \\mathbf{a}_4 - \\mathrm{proj}_{\\mathbf{q}_1} \\mathbf{a}_4 - \\mathrm{proj}_{\\mathbf{q}_2} \\mathbf{a}_4 - \\mathrm{proj}_{\\mathbf{q}_3} \\mathbf{a}_4\n",
    "\n",
    "    \\\\ \\\\\n",
    "\n",
    "    \\mathbf{q}_n = \\mathbf{a}_n - \\mathrm{proj}_{\\mathbf{q}_1} \\mathbf{a}_n - \\cdots - \\mathrm{proj}_{\\mathbf{q}_{n-1}} \\mathbf{a}_n\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "_Key:_\n",
    "\n",
    "$\n",
    "\\mathbf{a}_n \\Leftarrow \\text{column } n \\text{ from input matrix } \\mathbf{A}\n",
    "$\n",
    "\n",
    "$\n",
    "\\mathbf{q}_n \\Leftarrow \\text{column } n \\text{ orthogonalized vector before normalization }\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After orthogonalizing each column $i$, divide by its magnitude to normalize to unit length:\n",
    "\n",
    "$\n",
    "\\LARGE\n",
    "    \\hat{\\mathbf{q}}_i = \\frac{\\mathbf{q}_i}{\\left\\Vert \\mathbf{q}_i \\right\\Vert}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 90%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Code:_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix dimensions:\n",
    "m_rows = 5\n",
    "n_cols = 5\n",
    "\n",
    "# Generate random normal matrix:\n",
    "A = np.random.randn(m_rows, n_cols)\n",
    "\n",
    "# Initialize matrix Q with zeros, same shape as A:\n",
    "Q = np.zeros_like(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Visualize Creation of $Q$ and Its Orthonormal Columns:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row shows current Q matrix at col 0. Columns 1+\n",
    "#  show the step-by-step construction of Q[:, i]:\n",
    "fig, axes = plt.subplots(n_cols, n_cols + 1, figsize=(m_rows * 2, n_cols * 2))\n",
    "\n",
    "for i in range(n_cols):\n",
    "    # Begin with i-th column of original matrix A:\n",
    "    col_to_compute = A[:, i]\n",
    "\n",
    "    # Column 1: original unprocessed A[:, i]:\n",
    "    axes[i][1].imshow(col_to_compute.reshape(-1, 1), cmap='viridis')\n",
    "    init_col_title = f\"\\n$A[:, {i}]$\"\n",
    "    if i == 0:\n",
    "        init_col_title += f\"$ \\\\approx Q[:, {i}]$\"\n",
    "    axes[i][1].set_title(init_col_title)\n",
    "\n",
    "    # Progressively subtract parallel vectors onto previously\n",
    "    #  computed Q column vectors:\n",
    "    for j in range(i):\n",
    "        # j-th orthonormal vector:\n",
    "        ref_col = Q[:, j]\n",
    "\n",
    "        # Compute parallel component:\n",
    "        parallel = np.dot(col_to_compute, ref_col) / np.dot(ref_col, ref_col) * ref_col\n",
    "\n",
    "        # Subtract parallel component to get orthogonal component:\n",
    "        col_to_compute -= parallel\n",
    "\n",
    "        # Display the intermediate state to see the building process:\n",
    "        axes[i][j + 2].imshow(col_to_compute.reshape(-1, 1), cmap='viridis')\n",
    "        step_title = f\"\\nQ[:, {i}]\"\n",
    "        if j == i - 1:\n",
    "            step_title += \" Final Step\"\n",
    "        else:\n",
    "            step_title += f\" Step {j + 1}\"\n",
    "        axes[i][j + 2].set_title(step_title)\n",
    "\n",
    "    # Normalize the computed vector to unit length\n",
    "    #  to ensure Q remains an orthonormal matrix:\n",
    "    col_to_compute = col_to_compute / np.linalg.norm(col_to_compute)\n",
    "\n",
    "    # Store in orthogonal matrix Q:\n",
    "    Q[:, i] = col_to_compute\n",
    "\n",
    "    # Show current state of matrix Q:\n",
    "    axes[i][0].imshow(Q, cmap='viridis')\n",
    "    if i == n_cols - 1:\n",
    "        q_title = \"\\n$Q$ (complete)\"\n",
    "    else:\n",
    "        q_title = \"\\n$Q$ (so far)\"\n",
    "    axes[i][0].set_title(q_title)\n",
    "\n",
    "# Remove axis ticks, borders and labels from\n",
    "#  subplots for cleaner visualization:\n",
    "for axis in axes.ravel():\n",
    "    axis.set_axis_off()\n",
    "\n",
    "# Add title:\n",
    "fig.suptitle(\"Gram-Schmidt Orthonormalization\\nStep-by-Step Visualization\", fontsize=20)\n",
    "\n",
    "# Clean up and space the layout:\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show it:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Compare Manual Gram-Schmidt Build With `np.linalg.qr()` Version:_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_QR, R_QR = np.linalg.qr(A)\n",
    "\n",
    "print(\"Manual G-S Q and np.linalg.qr(), rounded for visual inspection:\")\n",
    "print(np.round(Q, 2))\n",
    "print(np.round(Q_QR, 2))\n",
    "print()\n",
    "\n",
    "# Compare manual Q with NumPy's built-in QR decomposition:\n",
    "print(\"Manual and NumPy matrices match precisely?\")\n",
    "Q_COMP = np.abs(np.round(Q, 13))\n",
    "Q_QR_COMP = np.abs(np.round(Q_QR, 13))\n",
    "print(np.allclose(Q_COMP, Q_QR_COMP))\n",
    "print()\n",
    "\n",
    "# Should be the identity matrix:\n",
    "print(\"Manual Q @ Q.T returns the identity matrix?\")\n",
    "print(np.round(Q @ Q.T, 13))\n",
    "print()\n",
    "\n",
    "print(\"Q.T @ Q ~= ID via np.eye()?\")\n",
    "print(np.allclose(Q @ Q.T, np.eye(Q.shape[0])))\n",
    "print()\n",
    "\n",
    "plt.imshow(Q @ Q.T)\n",
    "plt.title(\"Diagonal identity structure?\\n$Q @ Q.T$ should $\\\\approx I$\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 90%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Outro:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple, I used a square matrix. However:\n",
    "\n",
    "-   The Gram-Schmidt procedure also applies to rectangular matrices.\n",
    "\n",
    "-   I plan to investigating the Gram-Schmidt process on matrix shape and rank given a non-square input.\n",
    "\n",
    "I'm also interested in exploring how NumPy implements `np.linalg.qr()`, including:\n",
    "\n",
    "-   The differences between its `reduced` and `complete` QR decompositions.\n",
    "\n",
    "-   The algorithms NumPy uses to make this work so effectively.\n",
    "\n",
    "-   Dr. Cohen explains that learning Gram-Schmidt is useful, but it has limitations in real-world applications. I'm interested to learn more about how NumPy overcomes these.\n",
    "\n",
    "Iâ€™m excited to see how these Linear Algebra concepts are used in Statistics, Machine Learning and other areas of AI.\n",
    "\n",
    "Future versions will include animating the Gram-Schmidt Procedure column by column, step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px crimson; width: 90%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px dodgerblue; width: 80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px #5EDC1F; width: 70%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px orangered; width: 60%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 0; box-shadow: 0 0 5px 4px gold; width: 50%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2>\n",
    "\n",
    "_Andrew Blais, Boston, Massachusetts_\n",
    "\n",
    "GitHub: https://github.com/andrewblais\n",
    "\n",
    "Website: https://www.andrewblais.dev/\n",
    "\n",
    "</font>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
